## 概念

时间片：每个进程被分配一个时间段，称作它的时间片，即该进程允许运行的时间。通常设为100ms。

进程：进程是操作系统进行资源分配的最小单位，包括CPU、内存空间、磁盘IO等。

线程：线程是进程的一个实体，是CPU调度和分配的基本单位。线程共享同一进程的全部资源。

吞吐量：单位时间内成功传送数据的数量。

## Thread

线程简单实现的三种方法

- 继承Thread类，覆盖run()方法。


- 实现Runnable接口，实现run()方法。


- 实现Callable接口，实现call()方法。（有返回结果）

```
public class ThreadC implements Callable<String> {
    @Override
    public String call() throws Exception {
        //do something
        return "result";
    }
}
    public static void main(String[] args) {
        ThreadC c = new ThreadC();
        FutureTask<String> faeature = new FutureTask<String>(c);
        new Thread(faeature).start();
    }

```

#### 线程的生命周期

线程的生命周期有五个状态：new , runnable , running , blocked , dead .

1. 新建（new）：创建一个Thread类的实例对象时，线程进入新建状态（未被启动），处于新建状态的线程有自己的内存空间，但是并没有运行。此时线程还不是活着的（not alive）
2. 就绪（runnable）：线程已经被启动，正在等待被分配给CPU时间片。调用start方法线程进入就绪状态，但部一定立即执行，此时处于就绪队列，线程时活着的（alive）
3. 运行（running）：线程获得CPU资源正在执行任务（run()方法），此时除非此线程自动放弃CPU资源或者有优先级更高的线程进入，线程将一直运行到结束。此时线程时活着的（alive）
4. 阻塞（blocked）：由于某种原因导致正在运行的线程让出CPU资源并暂停自己的执行，进入阻塞状态调用以下几种方法可以时线程进入阻塞状态sleep 、wait() /notify恢复、suspend()/resume恢复，处于阻塞状态的线程依然时活着的（alive）
5. 死亡（dead）：当线程执行完毕或者被其他线程杀死，线程进入死亡状态，这时线程不可能再进入就绪状态等待执行，死亡状态的线程不是或者的（not alive）

#### 守护线程

守护线程可以理解为后台运行线程，进程结束，守护线程就会结束，不需要手动的去关系和通知其状态。

守护线程与普通线程的写法上基本没有区别，只需要再调用start方法前将线程设置（setDaemon(true)）为守护线程即可。

#### 线程组和线程池的区别

他们的作用不同，线程组是为了方便线程的管理，线程池是为了管理线程的生命周期，复用线程，减少创建线程的开销。

#### ThreadLocal

当前线程副本ThreadLocal，当使用ThreadLocal修饰变量时，ThreadLocal为每个使用该变量的线程提供独立的变量副本，所以每一个线程都可以独立的改变自己的副本而不影响其他线程对于的副本。

ThreadLocal的实现原理是，先获取一个跟当前线程相关的ThreadLoaclMap，将变量设置到自己线程独立的ThreadLoaclMap中，所有操作都在自己的ThreadLoaclMap中进行，从而实现了不影响其他线程的副本。

#### 线程的异常处理

run()方法不允许throw exception，所有checked exception异常必须在run方法内try-catch处理。

对于unchecked exception 处理就需要用Thread里面的setUncaughtExceptionHandler(UncaughtExceptionHandler)方法进行处理。

实现步骤如下：

- 定义一个类实现UncaughtExceptionHandler接口。在实现方法里包含异常处理逻辑。
- 定义线程执行结构和逻辑。即定义一个普通线程。
- 创建和执行该子线程的方法中，在thread.start()语句前增加一个thread.setUncaughtExceptionHandler语句来实现处理逻辑的注册。

实现UncaughtExceptionHandler接口

```
public class ThreadExceptionHandler implements Thread.UncaughtExceptionHandler {

	//异常处理逻辑
    @Override
    public void uncaughtException(Thread t, Throwable e) {
        System.out.printf("An exception has been captured\n");
        System.out.printf("Thread: %s:\n",t.getId());
        System.out.printf("Exception: %s %s\n",e.getClass().getName(),e.getMessage());
        System.out.printf("Stack Trace: \n");
        e.printStackTrace(System.out);
        System.out.printf("Tread status: %s\n",t.getState());
    }
}
```

实现一个线程

```
public class TestExceptionThread implements Runnable {
    @Override
    public void run() {
        int number = Integer.parseInt("TT");
    }
}
```

创建线程并进行异常处理逻辑的注册

```
public class ThreadMain {
    public static void main(String[] args) {
        Thread thread = new Thread(new TestExceptionThread());
        //注册异常处理逻辑
        thread.setUncaughtExceptionHandler(new ThreadExceptionHandler());
        thread.start();
    }
}
```

#### 隐式锁synchronized

synchronized是java语音关键字，他的用法有切只有两种：

- 一是在方法声明时，放在范围操作符之后，返回类型声明之前

```
public synchronized void synMethod(){}
```

- 二是修饰代码块，对某一制定对象加锁

```
public int synMethod(){
  synchronized(this){
    //访问共享可变资源
      ...
  }
}
```

当在某个线程中执行这段代码块，该线程会获取对象lock的锁，从而使得其他线程无法同时访问该代码块。其中，lock 可以是 this，代表获取当前对象的锁，也可以是类中的一个属性，代表获取该属性的锁。特别地， 实例同步方法 与 synchronized(this)同步块 是互斥的，因为它们锁的是同一个对象。但与 synchronized(非this)同步块 是异步的，因为它们锁的是不同对象。

synchronized规则：

- 当一个线程正在访问一个对象的 synchronized 方法，那么其他线程不能访问该对象的其他 synchronized 方法。这个原因很简单，因为一个对象只有一把锁，当一个线程获取了该对象的锁之后，其他线程无法获取该对象的锁，所以无法访问该对象的其他synchronized方法。
- 当一个线程访问object的一个synchronized(this)同步代码块时，另一个线程仍然可以访问该object中的非同步代码块。
- 当一个线程访问object的一个synchronized(this)同步代码块时，其他线程对object中所有其他synchronized(this)同步代码块的访问都将被阻塞。
- 如果一个线程 A 需要访问对象 object1 的 synchronized 方法 fun1，另外一个线程 B 需要访问对象 object2 的 synchronized 方法 fun1，即使 object1 和 object2 是同一类型），也不会产生线程安全问题，因为他们访问的是不同的对象，所以不存在互斥问题。

特别地，每个类也会有一个锁，静态的 synchronized方法 就是以Class对象作为锁。另外，它可以用来控制对 static 数据成员 （static 数据成员不专属于任何一个对象，是类成员） 的并发访问。并且，如果一个线程执行一个对象的非static synchronized 方法，另外一个线程需要执行这个对象所属类的 static synchronized 方法，也不会发生互斥现象。因为访问 static synchronized 方法占用的是类锁，而访问非 static synchronized 方法占用的是对象锁，所以不存在互斥现象。

重入性： 一般地，当某个线程请求一个由其他线程持有的锁时，发出请求的线程就会阻塞。然而，由于 Java 的内置锁是可重入的，因此如果某个线程试图获得一个已经由它自己持有的锁时，那么这个请求就会成功。可重入锁最大的作用是避免死锁。

以下三种情况会释放锁：

- 占有锁的线程执行完了该代码块，然后释放对锁的占有；
- 占有锁线程执行发生异常，此时JVM会让线程自动释放锁；
- 占有锁线程进入 WAITING 状态从而释放锁，例如在该线程中调用wait()方法等。

#### 显示锁Lock

Lock是一个接口，提供了无条件的、可轮询的、定时的、可中断的锁获取操作，所有加锁和解锁的方法都时显示的。以下是 java.util.concurrent.locks包下主要常用的类与接口的关系：

![img](http://static.codeceo.com/images/2017/02/865a51dff69223f0cf5ad630e5ada1909.jpg)



Lock接口源码：

```
public interface Lock {
    void lock();
    void lockInterruptibly() throws InterruptedException;  // 可以响应中断
    boolean tryLock();
    boolean tryLock(long time, TimeUnit unit) throws InterruptedException;  // 可以响应中断
    void unlock();
    Condition newCondition();
}
```

 lock()、tryLock()、tryLock(long time, TimeUnit unit) 和 lockInterruptibly()都是用来获取锁的。

unLock()方法是用来释放锁的。

newCondition() 返回 绑定到此 Lock 的新的 Condition 实例 ，用于线程间的协作。



ReentrantLock时Lock的实现类，是一个互斥的同步器，它具有扩展能力。

Lock与synchronized比较

- Lock使用起来比较灵活
- Lock必须手动释放和开启锁，synchronized则不需要
- Lock只适用于代码块锁，而synchronized对象之间时互斥关系
- Lock的吞吐量比synchronized好

第一种：两个方法之间的锁是独立的

```
public class IndependentLock {
    public static void main(String[] args) {
        final Count ct = new Count();
        for (int i=0;i<2;i++){
            new Thread(){
                @Override
                public void run(){
                    ct.get();
                }
            }.start();
        }
        for (int i=0;i<2;i++){
            new Thread(){
                @Override
                public void run(){
                    ct.put();
                }
            }.start();
        }
    }
    static class Count{
        public void get(){
            final ReentrantLock lock = new ReentrantLock();//定义方法内独立锁
            try {
                lock.lock();//加锁
                System.out.println(Thread.currentThread().getName() + "get begin");
                Thread.sleep(1000L);
                System.out.println(Thread.currentThread().getName() + "get end");
                lock.unlock();//解锁
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        }

        public void put(){
            final ReentrantLock lock = new ReentrantLock();//定义方法内独立锁
            try {
            	lock.lock();
                System.out.println(Thread.currentThread().getName() + "put begin");
                Thread.sleep(1000L);
                System.out.println(Thread.currentThread().getName() + "put end");
                lock.unlock();
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        }
    }
}
```

运行结果如下

```
Thread-2put begin
Thread-3put begin
Thread-1get begin
Thread-0get begin
Thread-0get end
Thread-1get end
Thread-3put end
Thread-2put end
```

第二种：两个方法使用相同的锁

```
public class ShareLock {

    public static void main(String[] args) {
        final Count ct = new Count();
        for (int i = 0; i < 2; i++) {
            new Thread() {
                @Override
                public void run() {
                    ct.get();
                }
            }.start();
        }
        for (int i = 0; i < 2; i++) {
            new Thread() {
                @Override
                public void run() {
                    ct.put();
                }
            }.start();
        }
    }

    static class Count {
        final ReentrantLock lock = new ReentrantLock();//定义公用锁

        public void get() {
            try {
                lock.lock();//加锁
                System.out.println(Thread.currentThread().getName() + "get begin");
                Thread.sleep(1000L);
                System.out.println(Thread.currentThread().getName() + "get end");
                lock.unlock();//解锁
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        }

        public void put() {
            try {
                lock.lock();//加锁
                System.out.println(Thread.currentThread().getName() + "put begin");
                Thread.sleep(1000L);
                System.out.println(Thread.currentThread().getName() + "put end");
                lock.unlock();//解锁
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        }
    }

}
```

运行结果如下

```
Thread-0get begin
Thread-0get end
Thread-1get begin
Thread-1get end
Thread-2put begin
Thread-2put end
Thread-3put begin
Thread-3put end
```

#### 关键字volatile

//TODO

#### 原子操作

不会被线程阻塞，atomic（通过JNI（java native interface）为本地调用实现的）

基本类：AtomicInteger、AtomicLong、AtomicBoolean

引用类型：AtomicReference , AtomicStampedReference , AtomicMarkableReference

数组类型：AtomicIntegerArray , AtomicLongArray , AtomicReferenceArray

属性原子修改器：AtomicIntegerFieldUpdater , AtomicLongFieldUpdater , AtomicReferenceFieldUpdater 

### 线程安全的集合

#### java.util.concurrent.ConcurrentHashMap

ConcurrentHashMap继承与AbstractMap，实现了Map，java.io.Serializable 接口。

//TODO

#### java.util.concurrent.CopyOnWriteArrayList

CopyOnWriteArrayList

当增加元素时，使用Arrays.copyOf()来拷贝副本，在副本上增加元素，然后改变原引用指向副本。

读操作不需要加锁，而写操作需要加锁。

CopyOnWriteArrayList是一个线程安全的List，对于都操作远远多与写操作的应用非常合适，提供高性能的并发读取，并且保证读取内容正确。

#### java.util.concurrent.CopyOnWriteArraySet

CopyOnWriteArraySet是在CopyOnWriteArrayList基础上使用了java装饰模式。实现原理基于CopyOnWriteArrayList。

#### CopyOnWrite机制

CopyOnWrite容器即写时复制的容器。

应用场景：CopyOnWrite并发容器用于读多写少的并发场景。

缺点：

1. 内存占用问题。因为CopyOnWrite的写时复制机制，内存里需要占用两个对象的空间。
2. 数据一致性问题。CopyOnWrite容器只能保证数据的最终一致性，不能保证数据的实时一致性。所以如果写入的数据希望马上读到，请不要使用CopyOnWrite容器。

### 阻塞队列

Queue（队列）：线性列表，先进先出FIFO

Deque（双端队列）：栈结构，LIFO

#### ArrayBlockingQueue数组阻塞队列

ArrayBlockingQueue是一个由数组支持的有界的阻塞队列。此队列按FIFO先进先出原则。

特点：固定大小，支持可选公平策略。

```
BlockingQueue<T> queue = new ArrayBlockingQueue<T>(int capacity,boolean fair)
//capacity:队列的容量
//fair：是否启用公平策略
```

#### LinkedBlockingQueue链表的阻塞队列

LinkedBlockingQueue是基于链表的阻塞队列

#### PriorityBlockingQueue优先级阻塞队列

PriorityBlockingQueue是一个支持优先级排序的无界阻塞队列，

PriorityBlockingQueue并不会阻塞数据生产者，而只会在没有可消费的数据时，阻塞消费者。因此要注意生产者生产数据的速度不能快于消费者消费的速度，否则时间一长，会耗尽所有堆内存。

PriorityBlockingQueue内部控制线程同步的锁采用公平锁

#### DelayQueue延时队列

DelayQueue是一个支持延时获取元素的使用优先级的无界阻塞队列

DelayQueue中的元素必须实现Delayed接口和Comparable接口

通过public int compareTo(To)和long getDelay(TimeUnit unit)方法，在创建元素时指定延迟多久才能获取元素。只有在延迟期满才能获取队列中的元素。

应用场景：

- 缓存系统设计。可以用DelayQueue保存缓存元素的有效期，使用一个线程循环查询DelayQueue，一旦能从DelayQueue中获取元素时，表示缓存有效期到了。
- 定时任务调度。使用DelayQueue保存当天将会执行的任务和执行时间，一旦从DelayQueue中获取到任务就开始执行，比如TimerQueue就是使用DelayQueue实现的。

#### SynchronizedQueue同步队列

SynchronizedQueue是一个不存储元素的阻塞队列。每个put操作必须等带一个take操作，否则不能继续添加元素。

SynchronizedQueue是一个传球手，负责把生产者的数据直接传递给消费者，非常使用与传递性场景。

SynchronizedQueue的吞吐量高于LinkedBlockingQueue和ArrayBlockingQueue。

SynchronizedQueue声明方式由两种：公平模式和非公平模式。

#### LinkedBlockingDeque链表双向阻塞队列

#### LinkedTransferQueue链表传输队列

### 同步计数器CountDownLatch线程池

Executors是一个线程的工厂类。常用的线程池有三种

- newSingleThreadExecutor ：创建一个单线程的线程池
- newFixedThreadPool ：创建一个固定大小的线程池
- newCachedThreadPool ：创建一个可缓存的线程池

newSingleThreadExecutor 这个线程池里永远只有一个线程在工作，也就时相当于单线程串行执行所有任务。

```
ExecutorService executor = Executors.newSingleThreadExecutor();
	executor.execute(runnable);//执行线程
	executor.shutdown();//结束线程
```

newFixedThreadPool 这个线程池大小可以根据需要伸缩，可以重用之前构造的线程。对于执行很多短期异步任务而言，这个线程池可以提高程序性能。如果有可用线程，可重用以前构造的线程，如果没有可用线程，则创建一个新线程添加到池中。从缓存中移除那些已经由60s未被使用的线程。因此长时间保持空闲下线程池不会占用资源。

```
ExecutorService executor = Executors.newFixedThreadPool();
executor.execute(runnable);//执行线程
executor.shutdown();//结束线程  
```

newCachedThreadPool 同一时间内，只有固定数量的线程在工作。线程数量上升到固定数量就不变了，然后执行完之后逐渐释放。

```
ExecutorService executor = Executors.newCachedThreadPool();
executor.execute(runnable);//执行线程
executor.shutdown();//结束线程  
```

#### Executor主要类说明

![enter image description here](http://static.codeceo.com/images/2016/08/ccc9680e4fe52fdfb6e8dd1bec6c881b.jpg)

Executor : 线程池的顶级接口，严格意义上讲，Executor并不是线程池，而是一个执行线程的工具。

ExecutorService : 真正的线程池接口。继承了Executor接口。

AbstractExecutorService  : 实现了ExecutorService 接口的所有方法。

Executors：是个线程的工厂类，方便快速创建很多线程池。

ThreadPoolExecutor：ExecutorService 的默认实现，继承了AbstractExecutorService 。

ThreadPoolExecutor构造方法如下:

```
public ThreadPoolExecutor(int corePoolSize,
                              int maximumPoolSize,
                              long keepAliveTime,
                              TimeUnit unit,
                              BlockingQueue<Runnable> workQueue) {

        this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue,
             Executors.defaultThreadFactory(), defaultHandler);

}
```

- **corePoolSize**：线程池的核心线程数,线程池中运行的线程数也永远不会超过 corePoolSize 个,默认情况下可以一直存活。可以通过设置allowCoreThreadTimeOut为True,此时 **核心线程数就是0**,此时keepAliveTime控制所有线程的超时时间。
- **maximumPoolSize**：线程池允许的最大线程数;
- **keepAliveTime**： 指的是空闲线程结束的超时时间;
- **unit** ：是一个枚举，表示 keepAliveTime 的单位;
- **workQueue**：表示存放任务的BlockingQueue<Runnable队列。
- **BlockingQueue**:阻塞队列（BlockingQueue）是java.util.concurrent下的主要用来控制线程同步的工具。如果BlockQueue是空的,从BlockingQueue取东西的操作将会被阻断进入等待状态,直到BlockingQueue进了东西才会被唤醒。同样,如果BlockingQueue是满的,任何试图往里存东西的操作也会被阻断进入等待状态,直到BlockingQueue里有空间才会被唤醒继续操作。
   阻塞队列常用于生产者和消费者的场景，生产者是往队列里添加元素的线程，消费者是从队列里拿元素的线程。阻塞队列就是生产者存放元素的容器，而消费者也只从容器里拿元素。具体的实现类有LinkedBlockingQueue,ArrayBlockingQueued等。一般其内部的都是通过Lock和Condition([显示锁（Lock）及Condition的学习与使用](http://www.silencedut.com/2016/06/12/%E6%98%BE%E7%A4%BA%E9%94%81%EF%BC%88Lock%EF%BC%89%E5%8F%8ACondition%E7%9A%84%E5%AD%A6%E4%B9%A0%E4%B8%8E%E4%BD%BF%E7%94%A8/))来实现阻塞和唤醒。

ThreadPoolExecutor的任务调度逻辑如下：

![enter image description here](http://static.codeceo.com/images/2016/08/beeb8bc577fcec5df499c8cf1f56a31f.jpg)

从上图我们可以看出，当提交一个新任务到线程池时，线程池的处理流程如下：

- 首先线程池判断基本线程池是否已满，如果没满，创建一个工作线程来执行任务。满了，则进入下个流程。
- 其次线程池判断工作队列是否已满，如果没满，则将新提交的任务存储在工作队列里。满了，则进入下个流程。
- 最后线程池判断整个线程池是否已满，如果没满，则创建一个新的工作线程来执行任务，满了，则交给饱和策略来处理这个任务。

下面我们来看看ThreadPoolExecutor核心调度代码

```
public void execute(Runnable command) {
        if (command == null)
            throw new NullPointerException();
        int c = ctl.get();
        /**
        * workerCountOf(c)获取当前线程池线程总数
        * 当前线程数小于corePoolSize核心线程数时，会将任务通过addWorker(command, true)方法直接调度执行。
        * 否则进入下个if，将任务加入等待队列
        **/
        if (workerCountOf(c) < corePoolSize) {
            if (addWorker(command, true))
                return;
            c = ctl.get();
        }
        /**
        * workQueue.offer(command) 将任务加入等待队列。
        * 如果加入失败（比如有界队列达到上限或者使用了synchronousQueue）则会执行else。
        *
        **/
        if (isRunning(c) && workQueue.offer(command)) {
            int recheck = ctl.get();
            if (! isRunning(recheck) && remove(command))
                reject(command);
            else if (workerCountOf(recheck) == 0)
                addWorker(null, false);
        }
        /**
        * addWorker(command, false)直接交给线程池，
        * 如果当前线程已达到maximumPoolSize，则提交失败执行reject()拒绝策略。
        **/
        else if (!addWorker(command, false))
            reject(command);
    }
```

从上面的源码我们可以知道execute的执行步骤：

- 如果当前运行的线程少于corePoolSize，则创建新线程来执行任务（注意，执行这一步骤需要获取全局锁）。
- 如果运行的线程等于或多于corePoolSize，则将任务加入到BlockingQueue。
- 如果无法将任务假如BlockingQueue（队列已满），则创建新的线程来处理任务（注意，执行这一步骤需要获取全局锁）。
- 如果创建新线程将使当前运行的线程超出maximumPoolSize，任务将被拒绝，并调用RejectedExecutionHandler.rejectedExecution()方法。

ThreadPoolExecutor采取上述步骤的总体设计思路，是为了在执行execute()方法时，尽可能的避免获取全局锁（那将会是一个严重的 可伸缩瓶颈）。在ThreadPoolExecutor完成预热之后（当前运行的线程数大于等于corePoolSize），几乎所有的execute()方法调用都是执行步骤2，而步骤2不需要获取全局锁。

#### 线程池监控

线程池监控，需要自定义线程池继承ThreadPoolExecutor类，并且实现beforeExecute、afterExecute、和terminated方法。



## 参考阅读

本文部分内容参考自《Java并发编程从入门到精通》

码农网 http://www.codeceo.com